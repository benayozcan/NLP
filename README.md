# NLP
Sentiment analysis on movies with machine learning and deep learning

Sentiment analysis is a method for understanding people's feelings and emotions from texts, comments or images using software and artificial intelligence. Sentiment analysis (Idea Mining) is a general definition given to the processes of calculating and defining the attitude of an article towards a certain subject as positive, negative, neutral using various algorithms. It is an important tool that helps companies improve their products or services.

*Advantages of Sentiment Analysis:
Increases efficiency: Sentiment analysis helps businesses better understand and solve their customers' needs. 
Increases customer loyalty: Repeat customers and positive customer reviews are important factors that contribute to customer loyalty and revenue. 
Better customer service: Customer service teams can help customers better understand their needs and provide relevant customer service through two-way communication channels.
*Disadvantages of Sentiment Analysis:
Emotional Confusion: In some cases, people can simultaneously convey several emotions in their comments. This may cause the algorithm to make errors in interpretation.
Cultural Differences: Comments can lose their meaning due to cultural journeys.
Toning: Because of the intonation of words, the algorithm can be misleading. For example, the word "not good at all" has a negative meaning, but the same phrase can have a positive meaning when the intonation is changed.

LOGISTIC REGRESSION:
Logistic regression analysis is a regression method that provides classification. In logistic regression, the dependent variable (y) should consist of categorical data. According to the independent variables, the expected value of the dependent variable is obtained as probability. 
It is a simple and fast method. Types: Binary Logistic Regression (improved/not improved, effective/ineffective), Multiterm Logistic Regression (working/not working/retired), Sequential Logistic Regression (very effective/moderately effective/ineffective)

NAİVE BAYES:
Naive Bayes algorithm is a simple probability algorithm used for a classification problem. This algorithm assumes that each attribute in the dataset is evaluated independently of other attributes. 
Naive Bayes algorithm can be used in many application areas. For example, it can be used in spam filtering, document classification, sentiment analysis, and more.

RANDOM FOREST:
Random Forest is a widely used algorithm in the field of machine learning. 
Random forest algorithm is one of the supervised classification algorithms. It is used in both regression and classification problems. The algorithm aims to increase the classification value during the classification process by producing more than one decision tree. Random forest algorithm is the process of choosing the highest score among many decision trees that work independently of each other. 
The random forest algorithm reduces the problem of over-learning if you have enough trees. It requires little data preparation.

XGBOOST:
It is one of the most used algorithms in machine learning and data science projects. 
Random forest: Models the dataset using multiple decision trees. 
-Boosting Method -> It is based on the idea of ​​bringing weak learners together and revealing a strong learner. 
Gradient Boosting: The next tree tries to build a better model by focusing on the errors of the previous trees. A series of models in the form of a single predictive model are built on the residuals. 
XGBoost: It is a high-performance version of the Gradient Boosting algorithm optimized with various arrangements.

DEEP LEARNING:
Deep learning is a machine learning method that uses deep structures represented by artificial neural networks. Artificial neural networks are inspired by the working principles of nerve cells in the human brain and automatically learn patterns based on data. 
Deep learning is a subset of machine learning. Machine learning involves designing systems that perform specific tasks using data-driven algorithms, while deep learning provides higher performance by handling more complex structures and larger datasets. The basic building block in deep learning is artificial neural network. 
Artificial neural networks consist of a series of layers that process input data and produce output. Each layer receives the inputs, processes them with learnable weights, and passes the outputs to the other layer. These layers include the hidden layers and the output layer.
